#!/bin/bash

# ============================================
# SCRIPT DE LANCEMENT - SYSTÃˆME BIG DATA COMPLET
# Pipeline Smart City Traffic Analysis
# ============================================

echo "ğŸš€ DÃ‰MARRAGE DU SYSTÃˆME BIG DATA COMPLET"
echo "=========================================="
echo ""

# Fonction de vÃ©rification
check_service() {
    local service=$1
    local url=$2
    local max_attempts=30
    local attempt=1

    echo "ğŸ” VÃ©rification de $service..."

    while [ $attempt -le $max_attempts ]; do
        if curl -s --max-time 5 "$url" > /dev/null 2>&1; then
            echo "âœ… $service est opÃ©rationnel"
            return 0
        fi

        echo "â³ Attente de $service (tentative $attempt/$max_attempts)..."
        sleep 5
        ((attempt++))
    done

    echo "âŒ $service n'est pas accessible aprÃ¨s $max_attempts tentatives"
    return 1
}

# 1. ArrÃªter les services existants
echo "ğŸ›‘ ArrÃªt des services existants..."
docker compose -f docker-compose-airflow.yml down 2>/dev/null || true
docker compose down 2>/dev/null || true
echo "âœ… Services arrÃªtÃ©s"
echo ""

# 2. Lancer tous les services
echo "ğŸ—ï¸ Construction et lancement de tous les services..."
echo "Cela peut prendre plusieurs minutes..."
echo ""

docker compose -f docker-compose-final.yml up -d --build

if [ $? -ne 0 ]; then
    echo "âŒ Erreur lors du lancement des services"
    exit 1
fi

echo ""
echo "âœ… Services en cours de dÃ©marrage..."
echo ""

# 3. Attendre que les services soient prÃªts
echo "â³ Attente de l'initialisation complÃ¨te des services..."
sleep 30

# 4. VÃ©rifications des services
echo ""
echo "ğŸ” VÃ‰RIFICATION DES SERVICES"
echo "============================"

services_ok=true

# Airflow
if check_service "Airflow Web UI" "http://localhost:8081/health"; then
    echo "ğŸŒ Airflow: http://localhost:8081 (admin/admin)"
else
    services_ok=false
fi

# Grafana
if check_service "Grafana" "http://localhost:3000/api/health"; then
    echo "ğŸ“Š Grafana: http://localhost:3000 (admin/admin)"
else
    services_ok=false
fi

# HDFS
if check_service "HDFS NameNode" "http://localhost:9870"; then
    echo "ğŸ—„ï¸ HDFS NameNode: http://localhost:9870"
else
    services_ok=false
fi

# Spark
if check_service "Spark Master" "http://localhost:8090"; then
    echo "âš¡ Spark Master: http://localhost:8090"
else
    services_ok=false
fi

echo ""
echo "ğŸ“‹ Ã‰TAT FINAL"
echo "============="

if [ "$services_ok" = true ]; then
    echo "ğŸ‰ TOUS LES SERVICES SONT OPÃ‰RATIONNELS !"
    echo ""
    echo "ğŸš€ INSTRUCTIONS D'UTILISATION :"
    echo "=============================="
    echo ""
    echo "1ï¸âƒ£ Ouvrir Airflow: http://localhost:8081"
    echo "   â†’ Login: admin/admin"
    echo "   â†’ Cliquer sur 'smart_city_traffic_pipeline'"
    echo "   â†’ Cliquer sur 'Trigger DAG'"
    echo ""
    echo "2ï¸âƒ£ Observer l'exÃ©cution en temps rÃ©el"
    echo "   â†’ 11 tÃ¢ches sÃ©quentielles"
    echo "   â†’ DurÃ©e: 5-8 minutes"
    echo ""
    echo "3ï¸âƒ£ Voir les rÃ©sultats dans Grafana:"
    echo "   â†’ Heat Map GÃ©ographique"
    echo "   â†’ PrÃ©dictions ML temps rÃ©el"
    echo "   â†’ 23 panels de visualisation"
    echo ""
    echo "ğŸ¯ PIPELINE COMPLÃˆTE:"
    echo "   GÃ©nÃ©rateur â†’ Kafka â†’ HDFS â†’ Spark â†’ MySQL â†’ Grafana"
    echo ""
    echo "ğŸ† PROJET BIG DATA TERMINÃ‰ AVEC SUCCÃˆS !"
else
    echo "âš ï¸ Certains services ne sont pas encore prÃªts"
    echo ""
    echo "ğŸ”§ COMMANDES DE DIAGNOSTIC :"
    echo "docker compose -f docker-compose-final.yml ps"
    echo "docker compose -f docker-compose-final.yml logs airflow-webserver"
    echo "docker compose -f docker-compose-final.yml logs grafana"
    echo ""
    echo "ğŸ’¡ Attendre encore quelques minutes puis relancer ce script"
fi

echo ""
echo "=========================================="
echo "FIN DU SCRIPT DE LANCEMENT"
